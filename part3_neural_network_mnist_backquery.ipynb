{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version asks the network what the image should be, given a label\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit(), and its inverse logit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete on 1000 records\n",
      "training complete on 2000 records\n",
      "training complete on 3000 records\n",
      "training complete on 4000 records\n",
      "training complete on 5000 records\n",
      "training complete on 6000 records\n",
      "training complete on 7000 records\n",
      "training complete on 8000 records\n",
      "training complete on 9000 records\n",
      "training complete on 10000 records\n",
      "training complete on 11000 records\n",
      "training complete on 12000 records\n",
      "training complete on 13000 records\n",
      "training complete on 14000 records\n",
      "training complete on 15000 records\n",
      "training complete on 16000 records\n",
      "training complete on 17000 records\n",
      "training complete on 18000 records\n",
      "training complete on 19000 records\n",
      "training complete on 20000 records\n",
      "training complete on 21000 records\n",
      "training complete on 22000 records\n",
      "training complete on 23000 records\n",
      "training complete on 24000 records\n",
      "training complete on 25000 records\n",
      "training complete on 26000 records\n",
      "training complete on 27000 records\n",
      "training complete on 28000 records\n",
      "training complete on 29000 records\n",
      "training complete on 30000 records\n",
      "training complete on 31000 records\n",
      "training complete on 32000 records\n",
      "training complete on 33000 records\n",
      "training complete on 34000 records\n",
      "training complete on 35000 records\n",
      "training complete on 36000 records\n",
      "training complete on 37000 records\n",
      "training complete on 38000 records\n",
      "training complete on 39000 records\n",
      "training complete on 40000 records\n",
      "training complete on 41000 records\n",
      "training complete on 42000 records\n",
      "training complete on 43000 records\n",
      "training complete on 44000 records\n",
      "training complete on 45000 records\n",
      "training complete on 46000 records\n",
      "training complete on 47000 records\n",
      "training complete on 48000 records\n",
      "training complete on 49000 records\n",
      "training complete on 50000 records\n",
      "training complete on 51000 records\n",
      "training complete on 52000 records\n",
      "training complete on 53000 records\n",
      "training complete on 54000 records\n",
      "training complete on 55000 records\n",
      "training complete on 56000 records\n",
      "training complete on 57000 records\n",
      "training complete on 58000 records\n",
      "training complete on 59000 records\n",
      "training complete on 60000 records\n",
      "training on epoch 1 is complete\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 3\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    count = 0\n",
    "    for record in training_data_list:\n",
    "        count += 1\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        i1 = numpy.asarray(all_values[1:],dtype=numpy.float32)\n",
    "        #image_array = numpy.asarray(i1.reshape((28,28))) # for debugging\n",
    "        inputs = (i1 / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values \n",
    "        # (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        if count%1000 == 0: print(f'training complete on {count} records')\n",
    "        #if count == 20000: break\n",
    "        pass\n",
    "    pass\n",
    "    print(f'training on epoch {e+1} is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    i1 = numpy.asarray(all_values[1:],dtype=numpy.float32)\n",
    "    inputs = (i1 / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9546\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d2c5b620>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
